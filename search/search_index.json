{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to V2X E2E simulator","text":"<p>This project is a simulation system based on the AWSIM project, available on GitHub. It has been enhanced with a range of sensor types and a more realistic environment. One of the key study cases in this project is the simulation of autonomous buses, which incorporates a significant number of cameras to address blind spots during autonomous driving. Examples of applications for this simulation environment include analyzing the positioning of roadside unit sensors and bus sensors to enhance the vision of autonomous buses, as well as evaluating traffic metrics such as congestion due to the presence of autonomous buses within the city.</p> <p>Our Git repository is currently available</p>"},{"location":"#simulation-sample","title":"Simulation sample","text":""},{"location":"#extra-features","title":"Extra Features","text":"<ul> <li>Cyclists</li> <li>Pseudo sensors (computationally lightweight sensors)</li> <li>Additional patterns of movement</li> <li>New types of ROS messages</li> <li>Complete setup for an Autonomous Bus compatible with Autoware</li> <li>Enhanced Logging System compatible with OpenStreetMap</li> <li>Tools and techniques to improve the accuracy of 3D models by loading PCDs</li> </ul>"},{"location":"Components/Logger/","title":"Logs System","text":"<p>We have created two log systems. The first type is used for capturing data in specific areas and is named Log Area. The second type focuses on autonomous vehicles and is named Log Autonomous.</p>"},{"location":"Components/Logger/#log-area","title":"Log Area","text":"<p>This component is specifically focused on a defined area, as shown by the green box in the picture:</p> <p> Sample image of log area </p> <p>Log sample of Log area module</p> <p>The Sensor Name list contains the names of sensors that have a direct line of sight to the object within a specified distance. The vertical bar \"|\" has been used to separate elements in the list.</p> <p>The component saves the position, rotation, and time based on the Unity origin, as well as the observation state for cars or humans. This includes saving the color of the hint box around the car. We have also developed a short script that interprets and presents a heat map to better understand traffic and observation states based on this log (The code will be published soon).</p> <p>Green colors indicate objects that have been seen by the autonomous car, red indicates objects that have not been seen, and blue indicates objects that have been detected.</p> <p>You can find sample of this log in </p> <p>Location of Log Area components</p>"},{"location":"Components/Logger/#log-autonomous","title":"Log Autonomous","text":"<p>This component retrieves the name of the output file and the logging rate. It then saves position, speed, acceleration, collisions with humans, and collisions with other cars in CSV format based on the ROS world origin. To use this component, it must be attached to an autonomous vehicle to access the data and log it in a CSV file. The timestamp in the CSV file is derived from the ROS time class, which contains seconds and nanoseconds. Additionally, most of the physical features in the log are obtained from the RigidBody object, which is essential for autonomous car functionality.</p> <p>Log Autonomous component</p> <p>Sample of log file in csv</p> <p>hese areas look for 'NPCVehicle' and 'NPCPedestrian' in the objects that enter the zone. If the objects contain these components, they will start capturing data about the objects.</p>"},{"location":"Components/PCDScanner/Component/","title":"Lidar PCD Extractor Component","text":""},{"location":"Components/PCDScanner/Component/#prefab","title":"Prefab","text":"<p>To facilitate easier usage of this component, we have created a prefab located at:</p> <p></p>"},{"location":"Components/PCDScanner/Component/#lidar-types","title":"Lidar types","text":"<p>As shown in the image above, two types of sensors can be defined: dynamic and static lidar scanners.</p> <ul> <li>Dynamic Sensors: These sensors move with the car.</li> <li>Static Sensors: These sensors function as roadside unit sensors that remain stationary during the simulation.</li> </ul> <p>Ensure that all of these sensors, in addition to having the <code>Lidar Sensor</code> component (which all lidar sensors have in AWSIM), also have the <code>RGLScanAdapter</code> component. The code automatically finds these sensors and captures a shot from each position with the defined features on each of them.</p> <p></p>"},{"location":"Components/PCDScanner/Component/#vehicle-object","title":"Vehicle object","text":"<p>The <code>BusAutoware</code> object does not perform any functionality in this context and does not run according to the logic of an autonomous vehicle. Therefore, we have disabled all internal functionalities of this component. The purpose of this component is solely to provide realistic observations for dynamic sensors and to correctly represent blind spot positions. In other words, it acts merely as an obstruction of view, which is its intended role.</p> <p></p>"},{"location":"Components/PCDScanner/Component/#lidar-pcd-extractor","title":"Lidar PCD Extractor","text":"<p>This component is mainly responsible for methods to capture data. The first method uses lanelets: when using the lanelet option, the scanner moves along the lines of the lanelet and scans the positions. The difference of this package compared to the original one is that the shots are stored separately and don't accumulate together.</p> <p>The second method is using 'Read Poses From File'. When this option is set to true, you can use a CSV file as positions of the car. Then the system only captures the specific points that you have already inserted in the file. The file inputs positions and rotations.</p>"},{"location":"Components/PCDScanner/Component/#iteration","title":"Iteration","text":"<p>Iteration is the number of times that the test scenario is repeated. This feature helps to capture different types and conditions of cars, and also helps to collect complete data. The vehicle object has the 'Scanner Car' component, which is responsible for evaluating whether the state of the bus is reasonable or not. In case of collision of the bus with another object, or if the sensors intersect with another car, this capture will be denied (these cases occur because during these scan scenarios we only set the position of the car as specified in the file, and it may not be compatible with the current state which is actually available in the city).</p>"},{"location":"Components/PCDScanner/Component/#wait-after-each-scan","title":"Wait After Each Scan","text":"<p>We recommend setting it to <code>0</code>, but if you want to see the process work at a slower speed, set a number that you prefer.</p>"},{"location":"Components/PCDScanner/Component/#sensor-search","title":"Sensor Search","text":"<p>There is no need to assign it, but if you assign the Sensor Search component to the same object, it will use it and automatically find and fill it.</p> <p>The Sensor Search component is optional. This component will explore different setups of angles and positions and will create different states that could compare the results of each position in the final scans, which are separately captured.</p>"},{"location":"Components/PCDScanner/Component/#vehicle-game-object","title":"Vehicle Game Object","text":"<p>This is a reference to the vehicle object. Consider that this game object is just a symbol and does not need to have movement logic; the lidar extractor component will move it in the city.</p>"},{"location":"Components/PCDScanner/Component/#output-files-direction","title":"Output Files Direction","text":"<ul> <li>Output PCD File Path: The files of the lidar scan will be saved in the directory with the prefix that you have set at the end of this string.</li> <li>Output CSV File Path: In this directory, with this name, a CSV file will be created that shows the position, rotation, and extra information of sensors. This file is required to understand which PCD file is related to which experiment and which sensor.</li> </ul>"},{"location":"Components/PCDScanner/Component/#root-static-sensors","title":"Root Static Sensors","text":"<p>This is a reference to an object that is the parent of the static sensors. In the code, we will search the children of this object to find the static sensors.</p>"},{"location":"Components/PCDScanner/Component/#wait-time","title":"Wait Time","text":"<p>This is the time that the entire system lets the city run its traffic before sampling starts.</p>"},{"location":"Components/PCDScanner/Component/#log-around-the-car","title":"Log Around the Car","text":"<p>'Log Around the Car' is a component that is attached to the vehicle and saves the logs of cars which are near the car in the scan environment. You can leave it null or entirely ignore it, but it will save some data related to blind spots and cars or vehicles that are never seen or seen by which sensors.</p> <p> Lidar PCD Extractor and Sensor Search</p>"},{"location":"Components/PCDScanner/Package/","title":"PCD Scanner Package (old)","text":"<p>Scanner Package</p> <p> Note : The current separate package associated with this component is not updated, but it works well. Some parts of the description have been updated with new features. Therefore, use this documentation only if you are working with the old scanner package and not the latest complete package.</p> <p>This package is developed based on the \\\"PointCloudMapping\\\" system of Awsim, which is used to create a point cloud of a city. Our package aims to capture and save the point cloud of the city separately, point by point, but in a more realistic environment. This package can be used alongside the traffic system of the city to simulate input data when different traffic conditions are applied to the city.</p> <p>You may encounter an error when importing our package.</p> <p></p> <p>To resolve this, simply change the following line of code:</p> <p>Same for second error</p> <p></p> <p>How to use</p> <p>First, duplicate your base scene, which has a 3D map and can include the traffic system. In my case, I duplicated PointCloudMapping and renamed it to PointCloudScanner.</p> <p></p> <p>Now, go to Assets/ScannerPackage/Prefab and drag and drop the prefab into the scene.</p> <p></p> <p>Because we already have the RGL component in our prefab, we must remove the RGL Scene Manage component from the scene. In your case, if you are building your scene from scratch, you may not be required to do the same.</p> <p></p> <p>In the PointCloudScanner, there are two components: Point CloudMapper, which performs the normal scanning, and Lidar Pcd Extractor, which scans the environment frame by frame.</p> <p>Configuring the Components:</p> <p>This package supports multiple static and dynamic sensors. Dynamic sensors are the sensors carried by the car, while static sensors remain in the same place all the time during scanning.</p> <p>For example, in the image below, you can see we have three dynamic lidars on our car. Since the position of sensors is relative to the parent, it is possible to choose the position of each sensor independently. The log system will save the position of each sensor in each frame. However, you must ensure that sensor names are unique, as the log file saves data by the name of the sensor, and unique names are necessary for identification in the log file.</p> <p></p> <p>Similarly, we have two static lidars. Our code only checks the children of the \"Statics\" component. In this section, you can duplicate or add different sensors as needed.</p> <p></p> <p>** As you can see in the lidar object, the lidar objects in this prefab must have an RGL scan adapter. We recommend using our sensors and duplicating them to create new sensors to avoid missing this component. However, if you want to create it from scratch, you can manually add this component at the end of your components in the lidar or each sensor that you use.</p> <p></p> <p>The traffic system does not need to be inside our object and only needs to run simultaneously.</p> <p>For Developers: The logic of the code uses a box collider of the scanner car to detect whether it is inside a car or not. If it is outside the car, it will scan in that step. If not, it won't scan and will skip that step.</p> <p>Lidar PCD Extractor(in Point cloud scanner object)</p> <p></p> <p>Check the Path of PCD and CSV: The path is relative to the Asset file.</p> <p>Osm Container: This is the lanelet through which the scanner travels.</p> <p>Wait Time: This is the amount of time the system waits for the traffic system or other systems to start working. After this period, the process of capturing will begin.</p> <p>World Origin ROS: It is very important to configure this based on the real position of your map location. The default position of the package is set for Kashiwa, and you must edit this field according to your project.</p> <p>Lanelet Visualizer is Active: Controls the visibility of the path lines that cars travel through.</p> <p>Use CarPos: Hold off on using this feature as it does not work yet.</p>"},{"location":"Components/Pedestrian/","title":"Pedestrian &amp; Cyclists","text":""},{"location":"Components/Pedestrian/#pedestrian","title":"Pedestrian","text":"<p>Each pedestrian has three script components, as shown in the picture:</p> <ol> <li> <p>NPC  Pedestrian : This component handles and checks the physics behavior of the model. The log system uses this component to determine if an object is a human (this applies to cyclists as well).</p> </li> <li> <p>Simple PedestrianWalker Controller2 : This component enables NPCs to move and return over crosswalks</p> <ul> <li>Duration : Time of movement</li> <li>Speed : Speed of movement</li> <li>Traffic light : If this field is assigned, the character will check the color of the traffic light before moving into the street. If left null, the character skips this check and, after the duration time, will rotate and return to the initial position, looping this back-and-forth movement infinitely.</li> <li>Check Traffic Ligh Time : Frequency of scanning the traffic light state when character wants to cross the road.</li> <li>Wait Time : Duration of the character's waiting time when reaching the end of movement before starting to come back.</li> </ul> </li> </ol> <ol> <li> <p>Line of sight : Similar to the Vehcile section and psudo sensor section this component responsible to detecting system of our custom messages </p> <ul> <li>Points Parent : representitive points of pedestrian to better understand this section please look at the pesudo sensor section </li> <li>Cube : is a reference to the box which is around the character and show the sate of visibility</li> <li>Box State : is only for testing </li> </ul> </li> </ol> <p>Note To copy or create a new pedestrian in the city, you can duplicate the current pedestrians and configure them, or use the prefab located at ASSET/KashiwaPackage/Prefabs/LineOfSight</p>"},{"location":"Components/Pedestrian/#cyclists","title":"Cyclists","text":"<p>Cyclists have similar components compared to pedestrians, but there is one key difference: the \"Simple Pedestrian Walker Controller 2\" component is replaced with \"Simple Cyclist Movement\".</p>"},{"location":"Components/PseudoSensors/NoiseSetting/","title":"Noise Setting","text":"<p>Noise Setting is a singleton class responsible for creating noise for all the mock sensors. At the start of their operation, each sensor will check and obtain the related noise for itself.</p> <p>The numbers in the component show the amount of noise that will be added to the target signal, within a range of [-value, value], in a uniform distribution. The distribution of the noise is uniform and additive to the original values.</p> <p>As seen in the components, multiple types of noise can be defined with different factors. In the image below, a publisher sends four types of three-dimensional vectors with default noise. By default, if the name written in the field does not match any of the existing noises, it will return the first noise in the list. If the list of noises is empty, the system will consider the data as having no noise.</p>"},{"location":"Components/PseudoSensors/PseudoSensors/","title":"Pseudo Sensor","text":"<p>Pseudo sensors are designed to reduce the number of processes compared to real sensors such as lidar. Unlike real sensors that broadcast signals in all directions, pseudo sensors use line of sight. Rays are directly sent toward target objects that already have a line of sight, as illustrated in the picture below.</p> <p>Each pseudo sensor requires a Mock Sensor Object and a box collider. The box collider is used to calculate ray collisions.</p>"},{"location":"Components/PseudoSensors/PseudoSensors/#fields","title":"Fields:","text":"<ul> <li>Name : This field is used in the log system to identify which sensors have detected objects.</li> <li> <p>Category : This field categorizes sensors using a config file. If you prefer to manually set the position and features of the sensor in the Unity scene, you can ignore this field.</p> </li> <li> <p>Mock Sensor Type : This enum field determines if the sensor simulates a Camera or lidar and sets it in a bus or roadside.</p> </li> <li> <p>HFOV (Horizontal Field of View) : Specifies the horizontal field of view.</p> </li> <li> <p>VFOV (Vertical Field of View) : Specifies the vertical field of view.</p> </li> <li> <p>Sceen Objects : This field is for testing purposes and shows the detected objects during runtime.</p> </li> <li> <p>Max Distnace : Specifies the range of the rays.</p> </li> </ul>"},{"location":"Components/PseudoSensors/PseudoSensors/#other-configuration","title":"Other configuration:","text":"<p>At the end the pseudo sensor must be add to scenario this enable the system to detect  which object detect by which type of sensors</p>"},{"location":"Components/PseudoSensors/PseudoSensors/#how-it-works","title":"How it works","text":"<p>Each component that must be detected by a pseudo sensor must have the Line of Sight component. Objects with this component periodically check the Scenario component to determine if they have a line of sight to the sensor within their range. The line of sight is calculated using rays in Unity from the representative to the collider of the sensor, shown in the picture by arrows. Based on the number of points that can see the sensor, the box state for the object will be determined. The configuration of the number of required points to see a sensor, to be considered as a watched point, is defined in the Blind Scenario Manager component. In our case, the AutowareSimulator contains this component.</p> <p>Pedestrian component</p> <p>Configuration of thresholds</p> <p>These thresholds indicate how many representative points of an object must see the sensor to be considered as detected.</p>"},{"location":"Components/PseudoSensors/PseudoSensors/#color-states","title":"Color states","text":"<p>In our simulation, each car, pedestrian, or cyclist has three states. These states show how the autonomous car can observe these objects. The red state demonstrates that the car has no sense of the object. The purple or blue state means that RSUs (roadside units) detect the object, but the autonomous cars cannot see it. The green state indicates that the object is detected by the autonomous sensors.</p>"},{"location":"Components/PseudoSensors/PseudoSensors/#add-new-pseudo-sensor","title":"Add New Pseudo Sensor","text":"<ol> <li>Use the existing prefabs located in \\Assets\\KashiwaPackage\\Prefabs\\Pseudo Sensors.</li> <li>Modify the relevant fields based on your needs.</li> <li>Add the mock sensor to the scenario list of sensors.</li> </ol>"},{"location":"Components/PseudoSensors/PseudoSensorsSetup/","title":"How to setup RSU and OBU sensing by Pseudo sensors","text":""},{"location":"Components/PseudoSensors/PseudoSensorsSetup/#installation-guide-for-pseudo-sensor-setup-in-the-unity","title":"Installation Guide for Pseudo Sensor Setup in the Unity","text":"<ol> <li>Add the BlindManager.</li> <li>Add the Scenario.</li> <li> <p>Assign References:</p> </li> <li> <p>Verify that the prefabs in the RandomTraffic simulator are sourced from our prefab directory.</p> </li> <li>Create an OBU_Sensor as a child of sensor_kit_base_link (this is for management purposes only).</li> <li>Copy the prefabs and assign them to the OBU and the sensor list in the EgoVehicle.</li> <li>Create a similar setup object, as shown in the video, to handle RSUs.</li> <li>Add the prefabs from the specified directory.</li> <li>Similarly, assign the sensor to the RSU files and the sensor list in the EgoVehicle.</li> </ol>"},{"location":"Components/RSU/RSU/","title":"RSU (Road Side Unit)","text":"<p>In our project RSUs responsible to send data of mock sensor and traffic light which are related to them selves</p> <p>There are multi component that can be use in RSU </p> <p> RSU4 with 4 pesudo sensors </p> <p>Note : When using the RSUs, you may find other message components added to them. These components are in the testing phase and have not been completely configured. However, if you need to use them, you can complete their fields in the code. There is no need to do anything regarding publishing or similar tasks.</p>"},{"location":"Components/RSU/RSU/#custom-v2i-custom-v2i-publisher","title":"Custom V2I &amp; Custom V2I Publisher","text":"<p>These two components send data about traffic lights in their topics. They are very similar to V2I and V2I Publisher in AWSIM, with one main difference: these components send data based on a predefined list rather than using the distance from the autonomous vehicle.</p> <p> Components of RSUs </p>"},{"location":"Components/RSU/RSU/#predictedobjectsautoware-predictedobjectsnetworksim","title":"PredictedObjectsAutoware &amp;&amp; PredictedObjectsNetworkSim","text":"<p>These two components exactly work the same but final message format is different. they use a list of pseudo sensor and pridiocally scan the detected object list inside them and retrive the data of cars or humans detected by them and finally send the data in Hz that assigned to the component. These component also get the name of noise category and will apply the noise on output data when publishing ros message.</p> <p> PredictedObjectsAutoware component  </p>"},{"location":"Components/Vehicle/AddNewVehicle/","title":"Adding New Vehicle","text":"<p>Firstly, set up the vehicle based on the tutorial from AWSIM ( Awsim Link )</p> <ol> <li>Create an empty object under the \"sensorkit_base_link\"\" or any other object responsible for sensor data. Name the object \"perception_sensor\".</li> </ol> <ol> <li>Add \"Detected Object Autoware\" to the \"perception_sensor\".</li> </ol> <ol> <li> <p>Under the \"perception_sensor\" object, you can add mock sensors in two ways::</p> <ol> <li>Create them from scratch based on our documentation  link  </li> <li>Use the prefabs inside the <code>Assets\\KashiwaPackage\\Prefabs\\Pseudo Sensors</code></li> </ol> </li> <li> <p>You must add a reference to your sensor in the list of sensors within the \"Detected Objects Autoware\" component.</p> </li> </ol> <ol> <li> <p>The Bus Transform must reference the base link of your car for autonomous data capturing to work correctly in the ROS world and for relative data to be captured precisely.</p> </li> <li> <p>You are also required to add a reference to your sensors in the scenario component as shown in the picture. Be careful when selecting the correct list; you must choose the appropriate list and drag and drop the sensor onto it.</p> </li> </ol>"},{"location":"Contact/","title":"Contact us","text":""},{"location":"GettingStarted/SetupUnityProject/","title":"Setup Unity Project","text":"<p>Info</p> <p>It is advised to checkout the Quick Start Demo tutorial before reading this section.</p> <p>This page is a tutorial for setting up a AWSIM Unity project.</p>"},{"location":"GettingStarted/SetupUnityProject/#environment-preparation","title":"Environment preparation","text":""},{"location":"GettingStarted/SetupUnityProject/#system-setup","title":"System setup","text":"Ubuntu 22Windows <ol> <li>Make sure your machine meets the required hardware specifications.<ul> <li>NOTE: PC requirements may vary depending on simulation contents which may change as the simulator develops</li> </ul> </li> <li>Prepare a desktop PC with Ubuntu 22.04 installed.</li> <li>Install Nvidia drivers and Vulkan Graphics API.</li> <li>Install git.</li> <li> <p>Set the ROS 2 middleware and the localhost only mode in <code>~/.profile</code> (or, in <code>~/.bash_profile</code> or <code>~/bash_login</code> if either of those exists) file: <pre><code>export ROS_LOCALHOST_ONLY=1\nexport RMW_IMPLEMENTATION=rmw_cyclonedds_cpp\n</code></pre></p> <p>Warning</p> <p>A system restart is required for these changes to work.</p> </li> <li> <p>Set the system optimizations by adding this code to the very bottom of your <code>~/.bashrc</code> file: <pre><code>if [ ! -e /tmp/cycloneDDS_configured ]; then\n    sudo sysctl -w net.core.rmem_max=2147483647\n    sudo ip link set lo multicast on\n    touch /tmp/cycloneDDS_configured\nfi\n</code></pre></p> <p>Info</p> <p>As a result, each time you run the terminal (<code>bash</code> prompt), your OS will be configured for the best ROS 2 performance. Make sure you open your terminal at least one before running any instance of AWSIM (or Editor running the AWSIM).</p> </li> </ol> <ol> <li>Make sure your machine meets the required hardware specifications.<ul> <li>NOTE: PC requirements may vary depending on simulation contents which may change as the simulator develops</li> </ul> </li> <li>Prepare a desktop PC with Windows 10 or 11 (64 bit) installed.</li> <li>Install git.</li> <li>Install Microsoft Visual C++ Redistributable packages for Visual Studio 2015, 2017, 2019, and 2022 (X64 Architecture)</li> </ol>"},{"location":"GettingStarted/SetupUnityProject/#ros-2","title":"ROS 2","text":"<p>AWSIM comes with a standalone flavor of <code>Ros2ForUnity</code>. This means that, to avoid internal conflicts between different ROS 2 versions, you shouldn't run the Editor or AWSIM binary with ROS 2 sourced.</p> <p>Warning</p> <p>Do not run the AWSIM, Unity Hub, or the Editor with ROS 2 sourced.</p> Ubuntu 22 <ul> <li>Make sure that the terminal which you are using to run Unity Hub, Editor, or AWSIM doesn't have ROS 2 sourced.</li> <li>It is common to have ROS 2 sourced automatically with <code>~/.bashrc</code> or <code>~/.profile</code>. Make sure it is not obscuring your working environment:<ul> <li>Running Unity Hub from the Ubuntu GUI menu takes the environment configuration from <code>~/.profile</code>.</li> <li>Running Unity Hub from the terminal uses the current terminal configuration from <code>~/.profile</code> and <code>~/.bashrc</code>.</li> <li>Running Unity Editor from the UnityHub inherits the environment setup from the Unity Hub. </li> </ul> </li> </ul> <p>Warning</p> <p>Currently, there are cases where the Nvidia driver version is too high, resulting in Segmentation fault. In that case, please lower the Nvidia driver version (550 is recommended.)</p> <p>The easiest way to be sure about your version is by using 'Software &amp; Updates' in Ubuntu.</p> <p></p> Windows <ul> <li>Make sure your Windows environment variables are ROS 2 free.</li> </ul>"},{"location":"GettingStarted/SetupUnityProject/#unity-installation","title":"Unity installation","text":"<p>Info</p> <p>AWSIM's Unity version is currently 2021.1.7f1</p> <p>Follow the steps below to install Unity on your machine:</p> <ol> <li>Install UnityHub to manage Unity projects. Please go to Unity download page and download latest <code>UnityHub.AppImage</code>. </li> <li> <p>Install Unity 2021.1.7f1 via UnityHub.</p> <ul> <li>Open new terminal, navigate to directory where <code>UnityHub.AppImage</code> is download and execute the following command: <pre><code>./UnityHub.AppImage\n</code></pre></li> <li> <p>To install Unity Editor please proceed as shown on the images below  </p> </li> <li> <p>After successful installation the version will be available under the <code>Installs</code> tab in Unity Hub (your Unity6 can be different in minor version section).</p> </li> </ul> </li> </ol>"},{"location":"GettingStarted/SetupUnityProject/#open-awsim-project","title":"Open AWSIM project","text":"<p>To open the Unity AWSIM project in Unity Editor:</p> Using Unity HubUsing Terminal <ol> <li> <p>Make sure you have the AWSIM repository cloned and ROS 2 is not sourced.     <pre><code>git clone https://github.com/tlab-wide/V2X_E2E_Simulator.git\n</code></pre></p> </li> <li> <p>Launch UnityHub.     <pre><code>./UnityHub.AppImage\n</code></pre></p> <p>Info</p> <p>If you are launching the Unity Hub from the Ubuntu applications menu (without the terminal), make sure that system optimizations are set. To be sure, run the terminal at least once before running the Unity Hub. This will apply the OS settings.</p> </li> <li> <p>Open the project in UnityHub</p> <ul> <li> <p>Click the <code>Open</code> button </p> </li> <li> <p>Navigate the directory where the AWSIM repository was cloned to </p> </li> <li> <p>The project should be added to <code>Projects</code> tab in Unity Hub. To launch the project in Unity Editor simply click the <code>AWSIM</code> item </p> </li> <li> <p>The project is now ready to use </p> </li> </ul> </li> </ol> <ol> <li> <p>Enter the AWSIM directory (make sure ROS 2 is not sourced).     <pre><code>cd AWSIM\n</code></pre></p> </li> <li> <p>If your Unity Editor is in default location, run the project using the editor command.     <pre><code>~/Unity/Hub/Editor/2021.1.7f1/Editor/Unity -projectPath .\n</code></pre></p> <p>Info</p> <p>If your Unity Editor is installed in different location, please adjust the path accordingly.</p> </li> </ol> <p>Warning</p> <p>If you get the safe mode dialog when starting UnityEditor, you may need to install openssl.</p> <ol> <li>download libssl <code>$ wget http://security.ubuntu.com/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.13_amd64.deb</code></li> <li>install <code>sudo dpkg -i libssl1.0.0_1.0.2n-1ubuntu5.13_amd64.deb</code></li> </ol>"},{"location":"GettingStarted/SetupUnityProject/#import-external-packages","title":"Import external packages","text":"<p>To properly run and use AWSIM project in Unity it is required to download map package which is not included in the repository.</p> <ol> <li> <p>Download and import the latest Kashiwa unity package which is currently <code>Kashiwa_7.6.unitypackage</code></p> <p>Download Map files (unitypackage)</p> </li> <li> <p>In Unity Editor, from the menu bar at the top, select <code>Assets -&gt; Import Package -&gt; Custom Package...</code> and navigate the <code>Kashiwa_7.4.11.unitypackage</code> file.  </p> </li> <li><code>Nishishinjuku</code> package has been successfully imported under <code>Assets/AWSIM/Externals/</code>directory. </li> </ol> <p>Info</p> <p>The Externals directory is added to the <code>.gitignore</code> because the map has a large file size and should not be directly uploaded to the repository.</p> <p>*NOTE: There is a high probability that the engine may crash once during the installation of this package due to the excessive RAM required, but there is no problem, and the installation will complete after a minute.</p>"},{"location":"GettingStarted/SetupUnityProject/#run-the-demo-in-editor","title":"Run the demo in Editor","text":"<p>The following steps describe how to run the demo in Unity Editor:</p> <ol> <li>Open the <code>AutowareSimulation.unity</code> scene placed under <code>Assets/AWSIM/Scenes/Main</code> or <code>Assets/V2x/scenes/</code> directory</li> <li>Run the simulation by clicking <code>Play</code> button placed at the top section of Editor. </li> </ol> <p></p>"},{"location":"Introduction/CombinationWithAutoware/","title":"Cooperative Autoware","text":""},{"location":"Introduction/CombinationWithAutoware/#download","title":"Download","text":"<p>Cooperative Autoware</p>"},{"location":"Introduction/CombinationWithAutoware/#build","title":"Build","text":"<p>The repository comes as a workspace by itself. To build the workspace follow the steps below:</p> <ul> <li> <p>Clone this repository to some desired folder: <pre><code>git clone git@github.com:hoosh-ir/autoware.git\n</code></pre></p> </li> <li> <p>Navigate to the root of the workspace: <pre><code>cd autoware\n</code></pre></p> </li> <li> <p>Execute the ansible script to download and install system dependencies: <pre><code>./setup-dev-env.sh\n</code></pre></p> </li> <li> <p>Install ROS dependencies: <pre><code>source /opt/ros/humble/setup.bash\nrosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n</code></pre></p> </li> <li> <p>Build the workspace: <pre><code>colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release\n</code></pre></p> </li> </ul>"},{"location":"Introduction/CombinationWithAutoware/#memory-issues-at-build-time","title":"Memory Issues At Build Time","text":"<p>Building Autoware requires and enormous amount RAM (about 32GB). If you have insufficient memory, use the following commands to allocate 32GB of swap file: <pre><code># Optional: Check the current swapfile\nfree -h\n\n# Remove the current swapfile\nsudo swapoff /swapfile\nsudo rm /swapfile\n\n# Create a new swapfile\nsudo fallocate -l 32G /swapfile\nsudo chmod 600 /swapfile\nsudo mkswap /swapfile\nsudo swapon /swapfile\n\n# Optional: Check if the change is reflected\nfree -h\n</code></pre></p>"},{"location":"Introduction/CombinationWithAutoware/#additional-options-provided","title":"Additional Options Provided","text":"<p><code>lightweight_localisation_ndt:=true/false</code> <code>lightweight_perception_detection:=true/false</code> used along with <code>pseudo_sensing_topic:=&lt;AWSIM pseudo sensor topic&gt;</code> <code>lightweight_perception_traffic_light:=true/false</code> <code>cooperative_mode:=true/false</code></p>"},{"location":"LoadPCD/","title":"Loading PCD Files in Unity","text":"<p>Loading Point Cloud Data (PCD) files into Unity can be challenging and often requires a paid solution. In this project, we've utilized the Pcx repository available on GitHub. However, it's important to note that Pcx is primarily designed to work with <code>.ply</code> files. We recommend using CloudCompare to convert <code>.pcd</code> files to <code>.ply</code>.</p>"},{"location":"LoadPCD/#conversion-process-in-cloudcompare","title":"Conversion Process in CloudCompare","text":"<p>The first challenge of importing a PCD file into Unity is correcting the dimensions. You must apply the following transformation in the opening window when you import your file in CloudCompare.</p> <p></p> <p> Note : Sometimes, you may not find a similar opening. In this case, first save your model as a PLY file using CloudCompare, then load the PLY file again and continue with the steps below.</p> <p>When loading a PCD file into CloudCompare, pay close attention to the XYZ transformations, as illustrated below:</p> <p></p> <p>Ensure that you accurately fill out the input fields based on your data:</p> <p></p> <p>After configuring the transformations, save the file in the <code>.ply</code> binary format.</p>"},{"location":"LoadPCD/#integrating-ply-files-into-unity","title":"Integrating .PLY Files into Unity","text":"<p>To use the converted <code>.ply</code> files in Unity, you will first need to install PCX. Begin by locating the <code>manifest.json</code> file in the Unity project\u2019s <code>Packages</code> folder.</p> <p></p> <p> Note : After importing the model into Unity, you need to set the X scale to -1, so the model aligns exactly in the correct position.</p> <p>Once PCX is installed, you can drag and drop the <code>.ply</code> files into your Unity environment. However, for optimal performance, it is advisable to clean up previously added project files. This practice ensures a smoother engine performance and enhances the quality and placement of 3D models prior to conducting simulation tests.</p> <p></p>"},{"location":"NetSim/","title":"NetSim","text":"<p>This package is a network simulator. It is designed to create simulated packet loss and delay in the incoming message topics and simulate the network status.</p>"},{"location":"NetSim/#download-netsim","title":"Download NetSim","text":"<ul> <li>NetSim</li> </ul>"},{"location":"NetSim/#dependencies","title":"Dependencies","text":""},{"location":"NetSim/#ros-dependency","title":"ROS dependency","text":"<ul> <li>ROS2 humble</li> <li>autoware_auto_msgs</li> <li>v2x_msgs</li> <li>csv2</li> </ul>"},{"location":"NetSim/#build","title":"Build","text":"<ul> <li> <p>Install ROS2 and clone the <code>v2x_msgs</code> and <code>autoware_auto_msgs</code> into the <code>src</code> directory of a ROS2 workspace.</p> </li> <li> <p>Clone the repository into your ROS2 workspace's <code>src</code> folder: <pre><code>git clone --recurse-submodules git@github.com:hoosh-ir/net_sim.git\n</code></pre></p> </li> <li>Source your ROS2 Humble: <pre><code>source /opt/ros/humble/setup.bash\n</code></pre></li> <li>From the root of your workspace, use <code>colcon</code> to build the package: <pre><code>colcon build --symlink-install\n</code></pre></li> </ul>"},{"location":"NetSim/#run","title":"Run","text":"<ul> <li>From the root of your workspace, source your ROS2 workspace: <pre><code>. install/setup.bash\n</code></pre></li> <li>Configure the network simulator by modifying the parameters in the config file <code>config/net_sim_conf.yaml</code>.</li> <li>Launch the application: <pre><code>ros2 launch net_sim net_simulator.launch.py\n</code></pre></li> </ul>"},{"location":"NetSim/#configure","title":"Configure","text":""},{"location":"NetSim/#network-simulation-configurations","title":"Network Simulation Configurations","text":"<p>The <code>net_sim_conf.yaml</code> file located at <code>config</code> provides various configurations for the network simulator. Below, you'll find a list of the options:</p> <ul> <li> <p><code>network_status_type</code>: This parameter determines the type of the network status and can take the following values:</p> <ul> <li><code>0</code> (None): This value determines there are no delays or packet losses for the incoming topics.</li> <li><code>1</code> (Constant): In this mode, the simulator creates constant delay and packet loss for the message topics.</li> <li><code>2</code> (Heatmap): In this mode, the simulator reads a CSV file associated with a given network heatmap and creates delays and packet losses for the incoming message topics based on the heatmap values.</li> </ul> </li> <li> <p><code>const_network_delay</code>: This parameter determines the amount of constant delay (in milliseconds) to create for the incoming messages (Used only when the <code>network_status_type</code> is set to <code>1</code>).</p> </li> <li> <p><code>const_network_packet_loss</code>: This parameter determines the amount of constant packet loss (in percent) to create for the incoming messages (Used only when the <code>network_status_type</code> is set to <code>1</code>).</p> </li> <li> <p><code>prediction_network_status_file</code>: This parameter gives the absolute address of the heatmap file for the object prediction topic (Used only when the <code>network_status_type</code> is set to <code>2</code>).</p> </li> <li> <p><code>prediction_network_status_involved_stations</code>: This parameter lists the IDs of the RSUs involved in the heatmap file for the object prediction topic (Used only when the <code>network_status_type</code> is set to <code>2</code>).</p> </li> <li> <p><code>traffic_signal_network_status_file</code>: This parameter gives the absolute address of the heatmap file for the traffic signal topic (Used only when the <code>network_status_type</code> is set to <code>2</code>).</p> </li> <li> <p><code>traffic_signal_network_status_involved_stations</code>: This parameter lists the IDs of the RSUs involved in the heatmap file for the traffic signal topic (Used only when the <code>network_status_type</code> is set to <code>2</code>).</p> </li> <li> <p><code>freespace_network_status_file</code>: This parameter gives the absolute address of the heatmap file for the freespace topic (Used only when the <code>network_status_type</code> is set to <code>2</code>).</p> </li> <li> <p><code>freespace_network_status_involved_stations</code>: This parameter lists the IDs of the RSUs involved in the heatmap file for the freespace topic (Used only when the <code>network_status_type</code> is set to <code>2</code>).</p> </li> </ul>"},{"location":"NetSim/#topic-configurations","title":"Topic Configurations","text":"<p>Similarly, the <code>topic_conf.yaml</code> file in the <code>config</code> folder, provides the means to configure the package for the input/output topics. The parameters are listed below:</p> <ul> <li><code>input_objects_topic</code></li> <li><code>output_objects_topic</code></li> <li><code>input_signals_topic</code></li> <li><code>output_signals_topic</code></li> <li><code>input_freespaces_topic</code></li> <li><code>output_freespaces_topic</code></li> <li><code>vehicle_pose_topic</code></li> </ul>"},{"location":"NetSim/#network-heatmap","title":"Network Heatmap","text":"<p>When simulating the network status based on some given heatmap file, the provided file must abide by the format rules below:</p> <ul> <li>The heatmap file must be a COMMA-SEPARATED VALUES file</li> <li>The heatmap file must NOT include any descriptive headers</li> <li>The values must be in the order <code>x,y,z,rsu_1_delay,rsu_1_packet_loss,rsu_2_delay,rsu_2_packet_loss,...</code></li> </ul> <p>You can refer to a sample heatmap file located in the <code>sample</code> folder.</p>"},{"location":"NetSim/#custom-messages","title":"Custom Messages","text":"<p>You can assign NetSim custom messages of your own. For this purpose, you need to adjust a few things in the NetSim codebase and rebuild it.</p> <p>In the following sections, we'll explain the requirements and modifications to custom messages.</p>"},{"location":"NetSim/#custom-message-format-requirements","title":"Custom Message Format Requirements","text":"<p>Let's assume you have a message type other than those supported by NetSim. Let's name this message <code>CustomMessage</code>. To simulate the network passing such messages, you need to create a cooperative message type containing your <code>CustomMessage</code>. We call that <code>CooperativeCustomMessage</code>. The fields inside <code>CooperativeCustomMessage</code> must include:</p> <pre><code>uint64 station_id\nuint64 sensor_type\ngeometry_msgs/PoseStamped station_pose\ncustom_package/CustomMessage custom_message\n</code></pre> <p><code>station_id</code> is the ID of the RSU (or OBU) sending the message, <code>sensor_type</code> is the type of the sensor used to obtain the messages (not yet defined). <code>station_pose</code> is the whole pose of the transmitting RSU (or OBU) and <code>custom_message</code> is your desired message.</p> <p>Note</p> <p>The <code>CustomMessage</code> type can be any of the ROS built-in message types or from any <code>custom_package</code> created by third parties.</p>"},{"location":"NetSim/#modification-to-netsim-codebase","title":"Modification to NetSim Codebase","text":"<p>To have NetSim transmit the external message types, you need to make NetSim identify, subscribe to and publish them. We've provided the means for you just to make slight alterations.</p> <p>In the source code, under <code>src</code>, you need to modify the <code>net_simulator.cpp</code> file. There are three sections identifiable by the phrase <code>Custom message section</code>. Under each section, there are commented code snippets. You need to uncomment and modify them according to the name of your package and message type.</p> <ul> <li>The first section includes the message types. Modify according to your package and message type names</li> <li>The second section defines the variables needed to simulate the message. In this section, be wary of the name you pass to the network reporter node (\"custom_message\" by default). This name must repeat in <code>config/net_sim_conf.yaml</code>. Also, make sure you pass the proper input and output topic names to the sender (\"/output_custom_message\" by default) and the receiver (\"/input_custom_message\" by default) nodes.</li> <li>The last section passes the created ROS nodes to the multithreaded executor.</li> </ul>"},{"location":"NetSim/#modification-to-netsim-config-files","title":"Modification to NetSim Config Files","text":"<p>After uncommenting and modifying commented code snippets, you need to modify <code>config/net_sim_conf.yaml</code>. Again, we've provided two commented sections (search \"Custom message section\" in the file) for you to uncomment and modify according to your needs.</p>"},{"location":"NetSim/#modification-to-cmakeliststxt","title":"Modification to CMakeLists.txt","text":"<p>In the CMakeLists.txt, refer to <code>Custom message section</code>s: - In the first section, add your <code>CustomMessage</code> and <code>CooperativeCustomMessage</code> packages as needed. - In the second section, link your custom packages to NetSim's libraries.</p>"},{"location":"NetSim/#modification-to-packagexml","title":"Modification to package.xml","text":"<p>In <code>package.xml</code> refer to the <code>Custom message section</code>, uncomment its section and modify it according to the names of your <code>CustomMessage</code> and <code>CooperativeCustomMessage</code> packages. </p>"},{"location":"NetSim/#build-netsim","title":"Build NetSim","text":"<p>After the above steps, rebuild NetSim to reflect the changes made. Make sure to place your <code>CustomMessage</code> and <code>CooperativeCustomMessage</code> packages in the same workspace as <code>net_sim</code> to build together. Follow the build instructions to build the workspace.</p>"},{"location":"ProjectGuide/GitBranch/","title":"Git branch","text":"<p>The document presents the rules of branching adopted in the V2X-simulator and simple-av development process.</p>"},{"location":"ProjectGuide/GitBranch/#branches","title":"Branches","text":"branch explain main Stable branch. Contains all the latest releases. feature/*** Feature implementation branch created from <code>kashiwa</code>. After implementation, it is merged into <code>kashiwa</code>. fix/*** bug fix implementation branch created from <code>kashiwa</code>. After implementation, it is merged into <code>kashiwa</code>. doc/*** doc branch created from <code>kashiwa</code>. After implementation, it is merged into <code>kashiwa</code>. gh-pages Documentation hosted on GitHub pages."},{"location":"inProgressSections/","title":"In progress sections","text":""},{"location":"inProgressSections/#e2e_v2x_simulator-todos","title":"E2E_V2X_Simulator ToDos:","text":"<p>E2E_V2X_Simulator ToDos</p> <p>Simple AV ToDos</p>"}]}